#!/usr/bin/env python3
"""
AI-powered project update analyzer
Analyzes GitHub project changes and generates intelligent update summaries
"""

import os
import sys
import json
import subprocess
from datetime import datetime, timedelta
from pathlib import Path

def get_repo_changes(repo_path, days=1):
    """Get commits, PRs, and issues from the last N days"""
    
    os.chdir(repo_path)
    
    # Get commits since yesterday
    since_date = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")
    
    try:
        # Get commits
        commits = subprocess.check_output(
            f'git log --since="{since_date}" --oneline',
            shell=True,
            text=True
        ).strip().split('\n') if subprocess.check_output(
            f'git log --since="{since_date}" --oneline',
            shell=True,
            text=True
        ).strip() else []
        
        # Get detailed commit messages
        commit_messages = subprocess.check_output(
            f'git log --since="{since_date}" --format="%B"',
            shell=True,
            text=True
        ).strip() if commits else ""
        
        return {
            'commits': commits,
            'commit_messages': commit_messages,
            'commit_count': len([c for c in commits if c.strip()])
        }
    except Exception as e:
        print(f"Error fetching repo data: {e}", file=sys.stderr)
        return {
            'commits': [],
            'commit_messages': '',
            'commit_count': 0
        }

def analyze_updates(changes, subjects_config):
    """Analyze changes and categorize them with AI-like pattern matching"""
    
    if not changes['commit_count']:
        return None
    
    all_text = (changes['commit_messages'] + ' ' + ' '.join(changes['commits'])).lower()
    
    detected_subjects = []
    
    # Match keywords to subjects
    for subject in subjects_config:
        for keyword in subject['keywords']:
            if keyword.lower() in all_text:
                detected_subjects.append(subject)
                break
    
    # Remove duplicates
    detected_subjects = list({s['name']: s for s in detected_subjects}.values())
    
    if not detected_subjects:
        # If no specific category, default to Feature Updates
        detected_subjects = [s for s in subjects_config if s['name'] == 'Feature Updates']
    
    return {
        'has_updates': True,
        'commit_count': changes['commit_count'],
        'commits': changes['commits'],
        'detected_subjects': detected_subjects,
        'summary': _generate_summary(changes, detected_subjects)
    }

def _generate_summary(changes, subjects):
    """Generate an update summary based on detected subjects"""
    
    subject_names = [s['name'] for s in subjects]
    subjects_str = ', '.join(subject_names)
    
    summary_lines = [
        f"## Updates Found: {subjects_str}",
        f"\n**Commit Count:** {changes['commit_count']} commit(s) since last update\n"
    ]
    
    # Add recent commits
    if changes['commits']:
        summary_lines.append("### Recent Changes:")
        for commit in changes['commits'][:10]:  # Show first 10
            if commit.strip():
                summary_lines.append(f"- {commit.strip()}")
    
    # Add concern indicators
    summary_lines.append("\n### Status Indicators:")
    for subject in subjects:
        summary_lines.append(f"⚠️ **{subject['name']}**: {subject['description']}")
    
    summary_lines.append("\n---")
    summary_lines.append("*This post was automatically generated by AI analysis of project updates.*")
    
    return '\n'.join(summary_lines)

def load_subjects_config(config_path="_config/post_subjects.json"):
    """Load post subjects configuration"""
    
    if not os.path.exists(config_path):
        return []
    
    try:
        with open(config_path, 'r') as f:
            return json.load(f)
    except Exception as e:
        print(f"Error loading subjects config: {e}", file=sys.stderr)
        return []

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: python analyze_updates.py <repo_path> [days]")
        sys.exit(1)
    
    repo_path = sys.argv[1]
    days = int(sys.argv[2]) if len(sys.argv) > 2 else 1
    
    changes = get_repo_changes(repo_path, days)
    subjects_config = load_subjects_config()
    analysis = analyze_updates(changes, subjects_config)
    
    # Output as JSON for parent script to consume
    print(json.dumps(analysis, indent=2))
